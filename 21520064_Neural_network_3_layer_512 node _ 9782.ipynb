{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HRKj4XA5WMC"
      },
      "source": [
        "# **Tải dữ liệu** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK7KUNP4AmW5",
        "outputId": "591213bb-7f60-4a5b-b465-a464cc8c02c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlC3OM8f5iXx"
      },
      "source": [
        "# Import thư viện cần thiết\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CtnQpeohAORp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from random import randint\n",
        "from google.colab.patches import cv2_imshow\n",
        "np.random.seed()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWlDXuBC5oIL"
      },
      "source": [
        "# Quan sát dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "naKReMwCBXQg"
      },
      "outputs": [],
      "source": [
        "x_train = X_train.reshape(len(X_train), 28*28)\n",
        "x_test = X_test.reshape(len(X_test), 28*28)\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "Jff_S6le5sdy",
        "outputId": "6b2c91d9-c5da-45af-c523-a5639f2d76cb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F0B1815C910>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cv2_imshow(X_train[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I833KVsly4_h",
        "outputId": "e9a81658-6603-4123-cdd5-24abc7cdbb3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP4I7Iptzt4_",
        "outputId": "ea861bdc-6c06-4215-9c19-bb0cb4d9fa7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBpEe1vWz3SH",
        "outputId": "dc0a5ccc-43e9-4ddb-b9e4-4ab5efc49b29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
              "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
              "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
              "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
              "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
              "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
              "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
              "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
              "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
              "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
              "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
              "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
              "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
              "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
              "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
              "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
              "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
              "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
              "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wQHkYL_Emne",
        "outputId": "aa55ca7a-fb4b-44a4-e16c-6405f02a8b1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_ZQsf9S5x0d"
      },
      "source": [
        "# Tạo model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-SA-qIyMakYQ"
      },
      "outputs": [],
      "source": [
        "class NN:\n",
        "    first_layer = {}\n",
        "    second_layer = {}\n",
        "\n",
        "    def __init__(self, inputs, hidden, outputs):\n",
        "        self.first_layer['weight'] = np.random.randn(inputs, hidden) / np.sqrt(inputs)\n",
        "        self.first_layer['bias'] = np.random.randn(hidden, 1) / np.sqrt(hidden)\n",
        "        self.second_layer['weight'] = np.random.randn(hidden, outputs) / np.sqrt(hidden)\n",
        "        self.second_layer['bias'] = np.random.randn(outputs, 1) / np.sqrt(outputs)\n",
        "      \n",
        "        self.input_size = inputs\n",
        "        self.hid_size = hidden\n",
        "        self.output_size = outputs\n",
        "\n",
        "    def activfunc(self, Z, type = 'ReLU', deri = False):\n",
        "        if type == 'ReLU':\n",
        "            if deri == True: # neu co dao ham\n",
        "                return np.array([1 if i > 0 else 0 for i in np.squeeze(Z)])\n",
        "            else:\n",
        "                return np.array([i if i > 0 else 0 for i in np.squeeze(Z)])\n",
        "        elif type == 'Sigmoid':\n",
        "            if deri == True:\n",
        "                return 1/(1+np.exp(-Z))*(1-1/(1+np.exp(-Z)))\n",
        "            else:\n",
        "                return 1/(1+np.exp(-Z))\n",
        "        elif type == 'tanh':\n",
        "            if deri == True:\n",
        "                return \n",
        "            else:\n",
        "                return 1-(np.tanh(Z))**2\n",
        "        else:\n",
        "            raise TypeError('Invalid type!')\n",
        "\n",
        "    def Softmax(self,z):\n",
        "        return 1/sum(np.exp(z)) * np.exp(z)\n",
        "\n",
        "    def cross_entropy_error(self, y_hat, y):\n",
        "        return -np.log(y_hat[y])\n",
        "\n",
        "    def feedforward(self,x,y):\n",
        "        Z1 = np.dot(self.first_layer['weight'].T, x).reshape((self.hid_size,1)) + self.first_layer['bias'] # Z[1] = W[1] * X + b[1]\n",
        "        A1 = np.array(self.activfunc(Z1)).reshape((self.hid_size,1)) # A[1] = sigmoid(Z[1])\n",
        "        Z2 = np.dot(self.second_layer['weight'].T, A1).reshape((self.output_size,1)) + self.second_layer['bias'] # Z[2] = W[2] * A[1] + b[2]\n",
        "        y_hat = np.squeeze(self.Softmax(Z2))\n",
        "        error = self.cross_entropy_error(y_hat,y)\n",
        "        para = {\n",
        "            'Z1': Z1,\n",
        "            'A1': A1,\n",
        "            'Z2': Z2,\n",
        "            'y_hat': y_hat,\n",
        "            'error': error\n",
        "        }\n",
        "        return para\n",
        "\n",
        "    def predict(self, x):\n",
        "        return np.argmax(self.feedforward(x, 1)['y_hat'])\n",
        "\n",
        "    def back_propagation(self, x, y, f_result):\n",
        "        # onehot encoder cho y\n",
        "        E = np.array([0]*self.output_size).reshape((1, self.output_size))\n",
        "        E[0][y] = 1\n",
        "        dtmp = (f_result['y_hat'] - E).reshape((self.output_size,1)) \n",
        "        db2 = dtmp\n",
        "        dW2 = np.dot(dtmp, f_result['A1'].T)\n",
        "        delta = np.dot(self.second_layer['weight'], dtmp) * self.activfunc(f_result['Z1'], deri = True).reshape(self.hid_size, 1)\n",
        "        db1 = delta\n",
        "        dW1 = np.dot(db1.reshape((self.hid_size, 1)),x.reshape((1, 784)))\n",
        "\n",
        "        grad = {\n",
        "            'dW2':dW2,\n",
        "            'db2':db2,\n",
        "            'db1':db1,\n",
        "            'dW1':dW1\n",
        "        }\n",
        "        return grad\n",
        "\n",
        "    def optimize(self,b_result, learning_rate):\n",
        "        self.second_layer['weight'] -= learning_rate*b_result['dW2'].T\n",
        "        self.second_layer['bias'] -= learning_rate*b_result['db2']\n",
        "        self.first_layer['weight'] -= learning_rate*b_result['dW1'].T\n",
        "        self.first_layer['bias'] -= learning_rate*b_result['db1']\n",
        "\n",
        "\n",
        "    def loss(self,X_train,Y_train):\n",
        "        loss = 0\n",
        "        for n in range(len(X_train)):\n",
        "            y = Y_train[n]\n",
        "            x = X_train[n][:]\n",
        "            loss += self.feedforward(x,y)['error']\n",
        "        return loss / len(X_train)\n",
        "\n",
        "    def train(self, X_train, Y_train, num_iterations = 1000, learning_rate = 0.5):\n",
        "        # generate random list index for train\n",
        "        rand_indices = np.random.choice(len(X_train), num_iterations, replace=True)\n",
        "        \n",
        "        def l_rate(base_rate, ite, num_iterations, schedule = False):\n",
        "        # determine whether to use the learning schedule\n",
        "            if schedule == True:\n",
        "                return base_rate * 10 ** (-np.floor(ite/num_iterations*5))\n",
        "            else:\n",
        "                return base_rate\n",
        "\n",
        "        count = 1\n",
        "        loss_dict = {}\n",
        "        test_dict = {}\n",
        "        num_epochs = 1\n",
        "        for i in rand_indices:\n",
        "            f_result = self.feedforward(X_train[i], Y_train[i])\n",
        "            b_result = self.back_propagation(X_train[i], Y_train[i], f_result)\n",
        "            self.optimize(b_result, l_rate(learning_rate, i, num_iterations, True))\n",
        "            \n",
        "            if count % 1000 == 0:\n",
        "                print('Trained for {} times,'.format(count))\n",
        "                if count % 5000 == 0:\n",
        "                    loss = self.loss(X_train,Y_train)\n",
        "                    test, wrong_case = self.testing(x_test,y_test)\n",
        "                    print('Trained for {} epoch(s),'.format(num_epochs),'loss = {}, test = {}'.format(loss,test))\n",
        "                    loss_dict[str(count)]=loss\n",
        "                    test_dict[str(count)]=test\n",
        "                    num_epochs += 1\n",
        "                    \n",
        "            count += 1\n",
        "\n",
        "        print('Training finished!')\n",
        "        return loss_dict, test_dict\n",
        "\n",
        "    def testing(self, X_test, y_test):\n",
        "        wrong_case = []\n",
        "        total_correct = 0\n",
        "        for n in range(len(X_test)):\n",
        "            y = y_test[n]\n",
        "            x = X_test[n][:]\n",
        "            prediction = np.argmax(self.feedforward(x, y)['y_hat'])\n",
        "            if (prediction == y):\n",
        "                total_correct += 1\n",
        "            else: wrong_case.append(n)\n",
        "        print('Accuarcy Test: ',total_correct / len(X_test))\n",
        "        return total_correct/np.float(len(X_test)), wrong_case"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZYToTdR51xY"
      },
      "source": [
        "## Test thử các trường hợp khác nhau của hidden size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "TgVuptBGtRLC",
        "outputId": "2563119b-e39a-41d3-8adf-7de34431a710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained for 1000 times,\n",
            "Trained for 2000 times,\n",
            "Trained for 3000 times,\n",
            "Trained for 4000 times,\n",
            "Trained for 5000 times,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5120fa2d0fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mcost_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtests_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0macc_per_hidden_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-ba6159f9a0e5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, Y_train, num_iterations, learning_rate)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trained for {} times,'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                     \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trained for {} epoch(s),'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'loss = {}, test = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-ba6159f9a0e5>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, X_train, Y_train)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-ba6159f9a0e5>\u001b[0m in \u001b[0;36mfeedforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhid_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Z[1] = W[1] * X + b[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhid_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# A[1] = sigmoid(Z[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Z[2] = W[2] * A[1] + b[2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_iterations = 200000\n",
        "learning_rate = 0.01\n",
        "num_inputs = 28*28\n",
        "num_outputs = 10\n",
        "hidden_size = [32, 64, 128, 256, 512]\n",
        "acc_per_hidden_size = []\n",
        "# data fitting, training and accuracy evaluation\n",
        "for i in hidden_size:\n",
        "  model = NN(num_inputs, i, num_outputs)\n",
        "  cost_dict, tests_dict = model.train(x_train, y_train, num_iterations=num_iterations, learning_rate=learning_rate)\n",
        "  tmp, _ = model.testing(x_test, y_test)\n",
        "  acc_per_hidden_size.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfZ3SgAn7yl-",
        "outputId": "8c162242-bb0a-4be5-d21c-18c45eaef81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained for 1000 times,\n",
            "Trained for 2000 times,\n",
            "Trained for 3000 times,\n",
            "Trained for 4000 times,\n",
            "Trained for 5000 times,\n",
            "Accuarcy Test:  0.8962\n",
            "Trained for 1 epoch(s), loss = 0.3692832654266917, test = 0.8962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:138: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained for 6000 times,\n",
            "Trained for 7000 times,\n",
            "Trained for 8000 times,\n",
            "Trained for 9000 times,\n",
            "Trained for 10000 times,\n",
            "Accuarcy Test:  0.9319\n",
            "Trained for 2 epoch(s), loss = 0.2466527180132791, test = 0.9319\n",
            "Trained for 11000 times,\n",
            "Trained for 12000 times,\n",
            "Trained for 13000 times,\n",
            "Trained for 14000 times,\n",
            "Trained for 15000 times,\n",
            "Accuarcy Test:  0.9384\n",
            "Trained for 3 epoch(s), loss = 0.21250576905223176, test = 0.9384\n",
            "Trained for 16000 times,\n",
            "Trained for 17000 times,\n",
            "Trained for 18000 times,\n",
            "Trained for 19000 times,\n",
            "Trained for 20000 times,\n",
            "Accuarcy Test:  0.9413\n",
            "Trained for 4 epoch(s), loss = 0.19919896817518723, test = 0.9413\n",
            "Trained for 21000 times,\n",
            "Trained for 22000 times,\n",
            "Trained for 23000 times,\n",
            "Trained for 24000 times,\n",
            "Trained for 25000 times,\n",
            "Accuarcy Test:  0.9509\n",
            "Trained for 5 epoch(s), loss = 0.16260238325042237, test = 0.9509\n",
            "Trained for 26000 times,\n",
            "Trained for 27000 times,\n",
            "Trained for 28000 times,\n",
            "Trained for 29000 times,\n",
            "Trained for 30000 times,\n",
            "Accuarcy Test:  0.9415\n",
            "Trained for 6 epoch(s), loss = 0.1681500213951661, test = 0.9415\n",
            "Trained for 31000 times,\n",
            "Trained for 32000 times,\n",
            "Trained for 33000 times,\n",
            "Trained for 34000 times,\n",
            "Trained for 35000 times,\n",
            "Accuarcy Test:  0.9539\n",
            "Trained for 7 epoch(s), loss = 0.13751653701323513, test = 0.9539\n",
            "Trained for 36000 times,\n",
            "Trained for 37000 times,\n",
            "Trained for 38000 times,\n",
            "Trained for 39000 times,\n",
            "Trained for 40000 times,\n",
            "Accuarcy Test:  0.9567\n",
            "Trained for 8 epoch(s), loss = 0.12533017040766847, test = 0.9567\n",
            "Trained for 41000 times,\n",
            "Trained for 42000 times,\n",
            "Trained for 43000 times,\n",
            "Trained for 44000 times,\n",
            "Trained for 45000 times,\n",
            "Accuarcy Test:  0.9622\n",
            "Trained for 9 epoch(s), loss = 0.11194166807944095, test = 0.9622\n",
            "Trained for 46000 times,\n",
            "Trained for 47000 times,\n",
            "Trained for 48000 times,\n",
            "Trained for 49000 times,\n",
            "Trained for 50000 times,\n",
            "Accuarcy Test:  0.9667\n",
            "Trained for 10 epoch(s), loss = 0.09682690839353922, test = 0.9667\n",
            "Trained for 51000 times,\n",
            "Trained for 52000 times,\n",
            "Trained for 53000 times,\n",
            "Trained for 54000 times,\n",
            "Trained for 55000 times,\n",
            "Accuarcy Test:  0.9671\n",
            "Trained for 11 epoch(s), loss = 0.09700008467282402, test = 0.9671\n",
            "Trained for 56000 times,\n",
            "Trained for 57000 times,\n",
            "Trained for 58000 times,\n",
            "Trained for 59000 times,\n",
            "Trained for 60000 times,\n",
            "Accuarcy Test:  0.968\n",
            "Trained for 12 epoch(s), loss = 0.08898200883241324, test = 0.968\n",
            "Trained for 61000 times,\n",
            "Trained for 62000 times,\n",
            "Trained for 63000 times,\n",
            "Trained for 64000 times,\n",
            "Trained for 65000 times,\n",
            "Accuarcy Test:  0.9674\n",
            "Trained for 13 epoch(s), loss = 0.09133048116970297, test = 0.9674\n",
            "Trained for 66000 times,\n",
            "Trained for 67000 times,\n",
            "Trained for 68000 times,\n",
            "Trained for 69000 times,\n",
            "Trained for 70000 times,\n",
            "Accuarcy Test:  0.967\n",
            "Trained for 14 epoch(s), loss = 0.08889415251050622, test = 0.967\n",
            "Trained for 71000 times,\n",
            "Trained for 72000 times,\n",
            "Trained for 73000 times,\n",
            "Trained for 74000 times,\n",
            "Trained for 75000 times,\n",
            "Accuarcy Test:  0.9706\n",
            "Trained for 15 epoch(s), loss = 0.07577921142163953, test = 0.9706\n",
            "Trained for 76000 times,\n",
            "Trained for 77000 times,\n",
            "Trained for 78000 times,\n",
            "Trained for 79000 times,\n",
            "Trained for 80000 times,\n",
            "Accuarcy Test:  0.9721\n",
            "Trained for 16 epoch(s), loss = 0.07633034930812632, test = 0.9721\n",
            "Trained for 81000 times,\n",
            "Trained for 82000 times,\n",
            "Trained for 83000 times,\n",
            "Trained for 84000 times,\n",
            "Trained for 85000 times,\n",
            "Accuarcy Test:  0.9715\n",
            "Trained for 17 epoch(s), loss = 0.07398633106821548, test = 0.9715\n",
            "Trained for 86000 times,\n",
            "Trained for 87000 times,\n",
            "Trained for 88000 times,\n",
            "Trained for 89000 times,\n",
            "Trained for 90000 times,\n",
            "Accuarcy Test:  0.9713\n",
            "Trained for 18 epoch(s), loss = 0.0783190702803834, test = 0.9713\n",
            "Trained for 91000 times,\n",
            "Trained for 92000 times,\n",
            "Trained for 93000 times,\n",
            "Trained for 94000 times,\n",
            "Trained for 95000 times,\n",
            "Accuarcy Test:  0.9716\n",
            "Trained for 19 epoch(s), loss = 0.07028862368655463, test = 0.9716\n",
            "Trained for 96000 times,\n",
            "Trained for 97000 times,\n",
            "Trained for 98000 times,\n",
            "Trained for 99000 times,\n",
            "Trained for 100000 times,\n",
            "Accuarcy Test:  0.9733\n",
            "Trained for 20 epoch(s), loss = 0.06475354483297907, test = 0.9733\n",
            "Trained for 101000 times,\n",
            "Trained for 102000 times,\n",
            "Trained for 103000 times,\n",
            "Trained for 104000 times,\n",
            "Trained for 105000 times,\n",
            "Accuarcy Test:  0.9718\n",
            "Trained for 21 epoch(s), loss = 0.07470454437228197, test = 0.9718\n",
            "Trained for 106000 times,\n",
            "Trained for 107000 times,\n",
            "Trained for 108000 times,\n",
            "Trained for 109000 times,\n",
            "Trained for 110000 times,\n",
            "Accuarcy Test:  0.9733\n",
            "Trained for 22 epoch(s), loss = 0.06295431026944463, test = 0.9733\n",
            "Trained for 111000 times,\n",
            "Trained for 112000 times,\n",
            "Trained for 113000 times,\n",
            "Trained for 114000 times,\n",
            "Trained for 115000 times,\n",
            "Accuarcy Test:  0.9743\n",
            "Trained for 23 epoch(s), loss = 0.059943843647669935, test = 0.9743\n",
            "Trained for 116000 times,\n",
            "Trained for 117000 times,\n",
            "Trained for 118000 times,\n",
            "Trained for 119000 times,\n",
            "Trained for 120000 times,\n",
            "Accuarcy Test:  0.9738\n",
            "Trained for 24 epoch(s), loss = 0.06458116847016358, test = 0.9738\n",
            "Trained for 121000 times,\n",
            "Trained for 122000 times,\n",
            "Trained for 123000 times,\n",
            "Trained for 124000 times,\n",
            "Trained for 125000 times,\n",
            "Accuarcy Test:  0.9757\n",
            "Trained for 25 epoch(s), loss = 0.06032026007029963, test = 0.9757\n",
            "Trained for 126000 times,\n",
            "Trained for 127000 times,\n",
            "Trained for 128000 times,\n",
            "Trained for 129000 times,\n",
            "Trained for 130000 times,\n",
            "Accuarcy Test:  0.9732\n",
            "Trained for 26 epoch(s), loss = 0.06219630819741692, test = 0.9732\n",
            "Trained for 131000 times,\n",
            "Trained for 132000 times,\n",
            "Trained for 133000 times,\n",
            "Trained for 134000 times,\n",
            "Trained for 135000 times,\n",
            "Accuarcy Test:  0.9676\n",
            "Trained for 27 epoch(s), loss = 0.07155663917643398, test = 0.9676\n",
            "Trained for 136000 times,\n",
            "Trained for 137000 times,\n",
            "Trained for 138000 times,\n",
            "Trained for 139000 times,\n",
            "Trained for 140000 times,\n",
            "Accuarcy Test:  0.9736\n",
            "Trained for 28 epoch(s), loss = 0.0580283999624435, test = 0.9736\n",
            "Trained for 141000 times,\n",
            "Trained for 142000 times,\n",
            "Trained for 143000 times,\n",
            "Trained for 144000 times,\n",
            "Trained for 145000 times,\n",
            "Accuarcy Test:  0.9779\n",
            "Trained for 29 epoch(s), loss = 0.04943446524294645, test = 0.9779\n",
            "Trained for 146000 times,\n",
            "Trained for 147000 times,\n",
            "Trained for 148000 times,\n",
            "Trained for 149000 times,\n",
            "Trained for 150000 times,\n",
            "Accuarcy Test:  0.9735\n",
            "Trained for 30 epoch(s), loss = 0.060499543448076475, test = 0.9735\n",
            "Trained for 151000 times,\n",
            "Trained for 152000 times,\n",
            "Trained for 153000 times,\n",
            "Trained for 154000 times,\n",
            "Trained for 155000 times,\n",
            "Accuarcy Test:  0.9733\n",
            "Trained for 31 epoch(s), loss = 0.056959888662845445, test = 0.9733\n",
            "Trained for 156000 times,\n",
            "Trained for 157000 times,\n",
            "Trained for 158000 times,\n",
            "Trained for 159000 times,\n",
            "Trained for 160000 times,\n",
            "Accuarcy Test:  0.9786\n",
            "Trained for 32 epoch(s), loss = 0.04306917366120168, test = 0.9786\n",
            "Trained for 161000 times,\n",
            "Trained for 162000 times,\n",
            "Trained for 163000 times,\n",
            "Trained for 164000 times,\n",
            "Trained for 165000 times,\n",
            "Accuarcy Test:  0.9758\n",
            "Trained for 33 epoch(s), loss = 0.049760792486046646, test = 0.9758\n",
            "Trained for 166000 times,\n",
            "Trained for 167000 times,\n",
            "Trained for 168000 times,\n",
            "Trained for 169000 times,\n",
            "Trained for 170000 times,\n",
            "Accuarcy Test:  0.9766\n",
            "Trained for 34 epoch(s), loss = 0.044202897276524315, test = 0.9766\n",
            "Trained for 171000 times,\n",
            "Trained for 172000 times,\n",
            "Trained for 173000 times,\n",
            "Trained for 174000 times,\n",
            "Trained for 175000 times,\n",
            "Accuarcy Test:  0.9794\n",
            "Trained for 35 epoch(s), loss = 0.03741637436383657, test = 0.9794\n",
            "Trained for 176000 times,\n",
            "Trained for 177000 times,\n",
            "Trained for 178000 times,\n",
            "Trained for 179000 times,\n",
            "Trained for 180000 times,\n",
            "Accuarcy Test:  0.9761\n",
            "Trained for 36 epoch(s), loss = 0.04508418517979063, test = 0.9761\n",
            "Trained for 181000 times,\n",
            "Trained for 182000 times,\n",
            "Trained for 183000 times,\n",
            "Trained for 184000 times,\n",
            "Trained for 185000 times,\n",
            "Accuarcy Test:  0.9772\n",
            "Trained for 37 epoch(s), loss = 0.03988023462429231, test = 0.9772\n",
            "Trained for 186000 times,\n",
            "Trained for 187000 times,\n",
            "Trained for 188000 times,\n",
            "Trained for 189000 times,\n",
            "Trained for 190000 times,\n",
            "Accuarcy Test:  0.9767\n",
            "Trained for 38 epoch(s), loss = 0.044252622907010514, test = 0.9767\n",
            "Trained for 191000 times,\n",
            "Trained for 192000 times,\n",
            "Trained for 193000 times,\n",
            "Trained for 194000 times,\n",
            "Trained for 195000 times,\n",
            "Accuarcy Test:  0.9796\n",
            "Trained for 39 epoch(s), loss = 0.03641411907154771, test = 0.9796\n",
            "Trained for 196000 times,\n",
            "Trained for 197000 times,\n",
            "Trained for 198000 times,\n",
            "Trained for 199000 times,\n",
            "Trained for 200000 times,\n",
            "Accuarcy Test:  0.9766\n",
            "Trained for 40 epoch(s), loss = 0.041803841370117036, test = 0.9766\n",
            "Trained for 201000 times,\n",
            "Trained for 202000 times,\n",
            "Trained for 203000 times,\n",
            "Trained for 204000 times,\n",
            "Trained for 205000 times,\n",
            "Accuarcy Test:  0.9742\n",
            "Trained for 41 epoch(s), loss = 0.04836726883109245, test = 0.9742\n",
            "Trained for 206000 times,\n",
            "Trained for 207000 times,\n",
            "Trained for 208000 times,\n",
            "Trained for 209000 times,\n",
            "Trained for 210000 times,\n",
            "Accuarcy Test:  0.9768\n",
            "Trained for 42 epoch(s), loss = 0.03670057098957078, test = 0.9768\n",
            "Trained for 211000 times,\n",
            "Trained for 212000 times,\n",
            "Trained for 213000 times,\n",
            "Trained for 214000 times,\n",
            "Trained for 215000 times,\n",
            "Accuarcy Test:  0.9766\n",
            "Trained for 43 epoch(s), loss = 0.03838310925628946, test = 0.9766\n",
            "Trained for 216000 times,\n",
            "Trained for 217000 times,\n",
            "Trained for 218000 times,\n",
            "Trained for 219000 times,\n",
            "Trained for 220000 times,\n",
            "Accuarcy Test:  0.9789\n",
            "Trained for 44 epoch(s), loss = 0.03401608168229158, test = 0.9789\n",
            "Trained for 221000 times,\n",
            "Trained for 222000 times,\n",
            "Trained for 223000 times,\n",
            "Trained for 224000 times,\n",
            "Trained for 225000 times,\n",
            "Accuarcy Test:  0.9782\n",
            "Trained for 45 epoch(s), loss = 0.03739560560339394, test = 0.9782\n",
            "Trained for 226000 times,\n",
            "Trained for 227000 times,\n",
            "Trained for 228000 times,\n",
            "Trained for 229000 times,\n",
            "Trained for 230000 times,\n",
            "Accuarcy Test:  0.9789\n",
            "Trained for 46 epoch(s), loss = 0.03271307624585271, test = 0.9789\n",
            "Trained for 231000 times,\n",
            "Trained for 232000 times,\n",
            "Trained for 233000 times,\n",
            "Trained for 234000 times,\n",
            "Trained for 235000 times,\n",
            "Accuarcy Test:  0.9789\n",
            "Trained for 47 epoch(s), loss = 0.03199775846824403, test = 0.9789\n",
            "Trained for 236000 times,\n",
            "Trained for 237000 times,\n",
            "Trained for 238000 times,\n",
            "Trained for 239000 times,\n",
            "Trained for 240000 times,\n",
            "Accuarcy Test:  0.9788\n",
            "Trained for 48 epoch(s), loss = 0.037067322971490575, test = 0.9788\n",
            "Trained for 241000 times,\n",
            "Trained for 242000 times,\n",
            "Trained for 243000 times,\n",
            "Trained for 244000 times,\n",
            "Trained for 245000 times,\n",
            "Accuarcy Test:  0.9786\n",
            "Trained for 49 epoch(s), loss = 0.031179611331191324, test = 0.9786\n",
            "Trained for 246000 times,\n",
            "Trained for 247000 times,\n",
            "Trained for 248000 times,\n",
            "Trained for 249000 times,\n",
            "Trained for 250000 times,\n",
            "Accuarcy Test:  0.9781\n",
            "Trained for 50 epoch(s), loss = 0.02975566542298887, test = 0.9781\n",
            "Trained for 251000 times,\n",
            "Trained for 252000 times,\n",
            "Trained for 253000 times,\n",
            "Trained for 254000 times,\n",
            "Trained for 255000 times,\n",
            "Accuarcy Test:  0.9801\n",
            "Trained for 51 epoch(s), loss = 0.028963478544789402, test = 0.9801\n",
            "Trained for 256000 times,\n",
            "Trained for 257000 times,\n",
            "Trained for 258000 times,\n",
            "Trained for 259000 times,\n",
            "Trained for 260000 times,\n",
            "Accuarcy Test:  0.9753\n",
            "Trained for 52 epoch(s), loss = 0.04144533885541269, test = 0.9753\n",
            "Trained for 261000 times,\n",
            "Trained for 262000 times,\n",
            "Trained for 263000 times,\n",
            "Trained for 264000 times,\n",
            "Trained for 265000 times,\n",
            "Accuarcy Test:  0.9798\n",
            "Trained for 53 epoch(s), loss = 0.025674571715504187, test = 0.9798\n",
            "Trained for 266000 times,\n",
            "Trained for 267000 times,\n",
            "Trained for 268000 times,\n",
            "Trained for 269000 times,\n",
            "Trained for 270000 times,\n",
            "Accuarcy Test:  0.9809\n",
            "Trained for 54 epoch(s), loss = 0.025718050921808754, test = 0.9809\n",
            "Trained for 271000 times,\n",
            "Trained for 272000 times,\n",
            "Trained for 273000 times,\n",
            "Trained for 274000 times,\n",
            "Trained for 275000 times,\n",
            "Accuarcy Test:  0.9817\n",
            "Trained for 55 epoch(s), loss = 0.0245136174092077, test = 0.9817\n",
            "Trained for 276000 times,\n",
            "Trained for 277000 times,\n",
            "Trained for 278000 times,\n",
            "Trained for 279000 times,\n",
            "Trained for 280000 times,\n",
            "Accuarcy Test:  0.9818\n",
            "Trained for 56 epoch(s), loss = 0.02335234549373528, test = 0.9818\n",
            "Trained for 281000 times,\n",
            "Trained for 282000 times,\n",
            "Trained for 283000 times,\n",
            "Trained for 284000 times,\n",
            "Trained for 285000 times,\n",
            "Accuarcy Test:  0.9778\n",
            "Trained for 57 epoch(s), loss = 0.03349602113225138, test = 0.9778\n",
            "Trained for 286000 times,\n",
            "Trained for 287000 times,\n",
            "Trained for 288000 times,\n",
            "Trained for 289000 times,\n",
            "Trained for 290000 times,\n",
            "Accuarcy Test:  0.9807\n",
            "Trained for 58 epoch(s), loss = 0.02515785324653628, test = 0.9807\n",
            "Trained for 291000 times,\n",
            "Trained for 292000 times,\n",
            "Trained for 293000 times,\n",
            "Trained for 294000 times,\n",
            "Trained for 295000 times,\n",
            "Accuarcy Test:  0.9805\n",
            "Trained for 59 epoch(s), loss = 0.02390151433408215, test = 0.9805\n",
            "Trained for 296000 times,\n",
            "Trained for 297000 times,\n",
            "Trained for 298000 times,\n",
            "Trained for 299000 times,\n",
            "Trained for 300000 times,\n",
            "Accuarcy Test:  0.9782\n",
            "Trained for 60 epoch(s), loss = 0.026301931201013012, test = 0.9782\n",
            "Training finished!\n",
            "Accuarcy Test:  0.9782\n"
          ]
        }
      ],
      "source": [
        "num_iterations = 300000\n",
        "learning_rate = 0.01\n",
        "num_inputs = 28*28\n",
        "num_outputs = 10\n",
        "hidden_size = 512\n",
        "acc_per_hidden_size = []\n",
        "# data fitting, training and accuracy evaluation\n",
        "model = NN(num_inputs, hidden_size, num_outputs)\n",
        "cost_dict, tests_dict = model.train(x_train, y_train, num_iterations=num_iterations, learning_rate=learning_rate)\n",
        "tmp, _ = model.testing(x_test, y_test)\n",
        "acc_per_hidden_size.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gXsDBBKRWnvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee84aa0c-9619-4431-df24-786330c4d121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuarcy Test:  0.9782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:138: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "accuracy, wrong_case = model.testing(x_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCvo_SAn7-O3"
      },
      "source": [
        "## Visualize một số trường hợp sai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "Iy9AB_AeDCyc",
        "outputId": "58e12424-15ff-447e-f6c2-6fbb4728c7db"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axes = plt.subplots(ncols=10, sharex=False, \n",
        "    sharey=True, figsize=(10, 4))\n",
        "for i in range(10):\n",
        "    axes[i].set_title((y_test[wrong_case[i]], model.predict(x_test[wrong_case[i]])))\n",
        "    axes[i].imshow(X_test[wrong_case[i]], cmap='gray')\n",
        "    axes[i].get_xaxis().set_visible(False)\n",
        "    axes[i].get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ldxUPdq8DC8"
      },
      "source": [
        "## Dự đoán \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bML4r4U_xzSd",
        "outputId": "e6f99b3d-a7a6-4852-b3f7-9b8ca9503f25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(x_test[11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDi3zmGi4r4k",
        "outputId": "3b7c0390-14f7-4690-ac74-e5f205627f6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test[11]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "ptTzjMps45VV",
        "outputId": "f5a165cb-30cf-4e83-b77f-da4c7653aeac"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABIElEQVR4nM2QsUtCURTGfy+EQHgguPQeLxqK5lpC/weXWlyDiGiocGgJgyBobSsoW1uLmgoJAoUHluBQSEKgZUFDS0Jk53Jb8ul94hh0psP3u9893znw1zV8o05NZajLdqf07SDjulwmQlLXOULeHwjt7/zAOK4q9GmRTpMNpKRH5cF8VVfzAOw3PkTeNw0WbTaAyExT6beTun4e64WrsgfulsjTjgdnkuidOU0Nskv6KnMH1MxALjCZ5nCtDUC53Atty2Ildrzc2bkN3SNorXG08/vNwouRtigZ4q+fG3EAv2Vc2X2UDDglubZJ+V/mmlyo8yiQGh89UK0Qw6uowlwyuV0UdT9LuJyqiCgRycUDzQq6WHpiMac5qvb5/k/9AF+bZJFBxVz7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F0B14471290>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cv2_imshow(X_test[11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_0BKkxUuniG"
      },
      "outputs": [],
      "source": [
        "for i in range(len(hidden_size)):\n",
        "  print(\"Accuracy for %d hidden size: %0.3f\" % (hidden_size[i], acc_per_hidden_size[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ7gQGpO8OMg"
      },
      "source": [
        "## So sánh các iteration khác nhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCoRz288cvuI"
      },
      "outputs": [],
      "source": [
        "cost = []\n",
        "acc = []\n",
        "num_iter = []\n",
        "for i in cost_dict:\n",
        "  num_iter.append(i)\n",
        "  cost.append(cost_dict[i])\n",
        "for i in tests_dict:\n",
        "  acc.append(tests_dict[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "gMFSDSApOl61",
        "outputId": "cdf02022-1225-4c97-f879-9b00e0f0ff76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration = 10000: loss = 0.288, accuracy = 0.917%\n",
            "iteration = 20000: loss = 0.212, accuracy = 0.936%\n",
            "iteration = 100000: loss = 0.105, accuracy = 0.961%\n",
            "iteration = 200000: loss = 0.057, accuracy = 0.975%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f35fd6c78d0>"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"iteration = %d: loss = %0.3f, accuracy = %0.3f%s\" %(10000, cost_dict['10000'], tests_dict['10000'], '%'))\n",
        "print(\"iteration = %d: loss = %0.3f, accuracy = %0.3f%s\" %(20000, cost_dict['20000'], tests_dict['20000'], '%'))\n",
        "print(\"iteration = %d: loss = %0.3f, accuracy = %0.3f%s\" %(100000, cost_dict['100000'], tests_dict['100000'], '%'))\n",
        "print(\"iteration = %d: loss = %0.3f, accuracy = %0.3f%s\" %(200000, cost_dict['200000'], tests_dict['200000'], '%'))\n",
        "\n",
        "plt.plot(cost, label='loss_value')\n",
        "plt.plot(acc, label='test_accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "21520064 Neural_network 3 layer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}